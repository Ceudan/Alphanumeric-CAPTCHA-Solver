{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chars Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpgUuwmrWdTi"
      },
      "source": [
        "# Captcha Bypass\n",
        "\n",
        "**Team 99**\n",
        "\n",
        "Pranavbhai Patel\n",
        "\n",
        "Nicholas Leung\n",
        "\n",
        "Coden Mercurius\n",
        "\n",
        "Ravi Singh\n",
        "\n",
        "**Description**\n",
        "\n",
        "CAPTCHA, or Completely Automated Public Turing Test to Tell Computers and Humans Apart, is a challenge-response test that determines whether a user is authentic (human) or inauthentic (machine). They require users to authenticate themselves by retyping a character sequence prior to completing a request. This notebook implements a CAPTCHA bypass using deep learning. The team aims to investigate weaknesses and vulnerabilities of the CAPTCHA system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5bj7jdWkZ2K"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from skimage import io\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data\n",
        "import torchvision \n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpLX9Jc1Xl2o"
      },
      "source": [
        "## Part 1. Data Processing\n",
        "\n",
        "The dataset for this model is generated using the following library: https://github.com/lepture/captcha. No additional data augmentation is performed at this time. The code used to generate the dataset is found in the team private repo and is named `dataset_generator.py`.\n",
        "\n",
        "**Primary Dataset Characteristics:**\n",
        "- Uniform distribution of characters used\n",
        "- 36 characters, 0-9 and A-Z\n",
        "- 3000 captchas\n",
        "\n",
        "**Secondary Dataset:**\n",
        "- A dataset of a smaller character space is also availiable\n",
        "- 10 numerical characters, 0-9\n",
        "- 1981 captchas\n",
        "\n",
        "\n",
        "The generated datasets are availiable through the team private repo. Upload `alphanumeric_dataset.zip` or `numeric_dataset.zip` into the root session storage and run the below cells to unzip. Update the path as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OFzcO7AIeH1"
      },
      "source": [
        "segmentation_dataset_path = '/content/2Chars Labeled'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jHHqUmAHun2"
      },
      "source": [
        "!unzip /content/labelled_2Char.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmayY8JErN5z"
      },
      "source": [
        "#To delete a folder\n",
        "#!rm -rf '/content/3Chars_Partialy_Labeled'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M5-fDmhMaVo"
      },
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, directory):\n",
        "    self.directory = directory\n",
        "    self.images = os.listdir(directory)\n",
        "\n",
        "    self.transform = transforms.Compose(\n",
        "        [transforms.ToTensor()])\n",
        "\n",
        "  def __len__(self):\n",
        "    # Assumes each file in the dataset directory represents a data sample\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample_name = self.images[index]\n",
        "    sample_name_wo_extension = sample_name[0:-4] # Slice s.t. remove png file extension\n",
        "\n",
        "    # Read the image and represent it as a tensor\n",
        "    image = io.imread(self.directory + '/' + sample_name)\n",
        "    #print(image)\n",
        "    #image = self.transform(image)\n",
        "    image=torch.tensor(image)\n",
        "    image=image.float()\n",
        "    image=image.unsqueeze(0)\n",
        "    #print(image)\n",
        "\n",
        "    # Define label\n",
        "    name=sample_name_wo_extension.split(\" \")\n",
        "    #label = float(name[0]),float(name[1])\n",
        "    label = float(name[0])\n",
        "\n",
        "    return (image, torch.tensor(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGzF8YBvzBhk"
      },
      "source": [
        "def get_data_loaders(dataset, batch_size):\n",
        "\n",
        "  training_ratio = 0.7\n",
        "  validation_ratio = 0.15\n",
        "  # test_ratio implied\n",
        "\n",
        "  train_length = int(len(dataset) * training_ratio)\n",
        "  validation_length = int((len(dataset) - train_length) * (validation_ratio / ( 1 - training_ratio )))\n",
        "  test_length = len(dataset) - train_length - validation_length\n",
        "  \n",
        "  train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [train_length, validation_length, test_length], torch.Generator().manual_seed(10))\n",
        "\n",
        "  # REMINDER: Data is not shuffled per epoch, we may want this\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, num_workers=1)\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, num_workers=1)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=1)\n",
        "\n",
        "  return train_loader, valid_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn_e3FRQ2yBC"
      },
      "source": [
        "class Chars2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Chars2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,7,5,1,4)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(7, 14, 5,1, 4)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "\n",
        "        self.conv3 = nn.Conv2d(14, 28, 5,1, 4)\n",
        "        self.pool3 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(28, 56, 5,1, 4)\n",
        "        self.pool4 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(56, 70, 5,1, 4)\n",
        "        self.pool5 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(70, 80, 5,1, 4)\n",
        "        self.pool6 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2000, 100)\n",
        "        self.fc2 = nn.Linear(100, 1)\n",
        "\n",
        "        self.lrelu=torch.nn.LeakyReLU(-0.001)\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.pool1(self.lrelu(self.conv1(img)))\n",
        "        x = self.pool2(self.lrelu(self.conv2(x)))\n",
        "        x = self.pool3(self.lrelu(self.conv3(x)))\n",
        "        x = self.pool4(self.lrelu(self.conv4(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool5(self.lrelu(self.conv5(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool6(self.lrelu(self.conv6(x)))\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 2000)\n",
        "        x = self.fc2(self.lrelu(self.fc1(x)))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Lid_0kMtXr"
      },
      "source": [
        "class Chars3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Chars3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,7,5,1,2)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(7, 14, 5,1, 2)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(14, 28, 5,1, 2)\n",
        "        self.pool3 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(28, 56, 5,1, 2)\n",
        "        self.pool4 = nn.MaxPool2d(2,2)\n",
        "\n",
        "\n",
        "        self.conv5 = nn.Conv2d(56, 80, 5,1, 2)\n",
        "        \n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(2000, 130)\n",
        "        self.fc2 = nn.Linear(130, 2)\n",
        "\n",
        "        self.lrelu=torch.nn.LeakyReLU(-0.001)\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.pool1(self.lrelu(self.conv1(img)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool2(self.lrelu(self.conv2(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool3(self.lrelu(self.conv3(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool4(self.lrelu(self.conv4(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.lrelu(self.conv5(x))\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 2000)\n",
        "        x = self.fc2(self.lrelu(self.fc1(x)))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "903hbL00RsIA"
      },
      "source": [
        "def trainer(model,data, numepochs,lr):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr)\n",
        "\n",
        "    iters = []\n",
        "    losses = []\n",
        "    epochnum = 0\n",
        "    for epoch in range(numepochs):\n",
        "        totloss=0\n",
        "        index=1\n",
        "        for img, label in data:  \n",
        "            #if use_cuda and torch.cuda.is_available():\n",
        "                #imgs = imgs.cuda()\n",
        "                #labels = labels.cuda()\n",
        "            out = model(img) # forward pass\n",
        "            #label=label.unsqueeze(0)\n",
        "            #label=torch.reshape(label,out.shape)\n",
        "            #print(label,\" \",out)    \n",
        "            loss = criterion(out, label) # compute the total loss\n",
        "            loss.backward()  # backward pass (compute parameter updates)\n",
        "            optimizer.step()  # make the updates for each parameter\n",
        "            optimizer.zero_grad()  # a clean up step for PyTorch\n",
        "\n",
        "            totloss+=float(loss.item())\n",
        "            #print(totloss)\n",
        "            index+=1\n",
        "            \n",
        "        iters.append(epochnum)\n",
        "        #print(totloss)\n",
        "        losses.append(totloss/index)  \n",
        "        print(epochnum)\n",
        "        epochnum += 1\n",
        "        # save the current training information\n",
        "        # torch.save(model.state_dict(), model_path)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(iters, losses, label=\"Train\")\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkeQ9UwsmTGL"
      },
      "source": [
        "def getaccuracy(model,data):\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    index=1\n",
        "    totloss=0\n",
        "    epochnum = 0\n",
        "    for img, label in data:  \n",
        "        #if use_cuda and torch.cuda.is_available():\n",
        "            #imgs = imgs.cuda()\n",
        "            #labels = labels.cuda()\n",
        "        out = model(img) # forward pass\n",
        "        #label=label.unsqueeze(0)\n",
        "        #label=torch.reshape(label,out.shape)\n",
        "        out=torch.tensor([40])\n",
        "        loss = criterion(out, label) # compute the total loss\n",
        "\n",
        "        print(label,\" \",out)\n",
        "        print(loss)\n",
        "        \n",
        "        totloss+=float(loss.item())\n",
        "        index+=1\n",
        "            \n",
        "    losses= totloss/index  \n",
        "    print(\"Average loss is \",losses)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "369gvdfelzTC"
      },
      "source": [
        "# Instantiate dataset\n",
        "segmentation_dataset = SegmentationDataset(segmentation_dataset_path)\n",
        "train, valid, test = get_data_loaders(segmentation_dataset, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT0-yZa7Nkg1"
      },
      "source": [
        "#save model\n",
        "#torch.save(model.state_dict(), '3Char.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbfWFZWbQQNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973f75db-84cd-405d-8eaa-73d18a9c13db"
      },
      "source": [
        "#Load Model\n",
        "model=Chars2()\n",
        "model.load_state_dict(torch.load('2Char.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvls-9OGoID7"
      },
      "source": [
        "\"\"\"CLICK ONLY ONCE\"\"\"\n",
        "#New Model\n",
        "model=Chars2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCKDNzt-r_35"
      },
      "source": [
        "\n",
        "trainer(model,valid,1000,0.000005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC3QIR6NxCGn",
        "outputId": "545bdf07-07e1-4d6d-d245-a8bad5b2957d"
      },
      "source": [
        "torch.set_printoptions(edgeitems=1000)\n",
        "getaccuracy(model,test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([43.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([43.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([32.])   tensor([40])\n",
            "tensor(64.)\n",
            "tensor([39.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([39.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([43.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([39.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([43.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([34.])   tensor([40])\n",
            "tensor(36.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([33.])   tensor([40])\n",
            "tensor(49.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([30.])   tensor([40])\n",
            "tensor(100.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([39.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([43.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([33.])   tensor([40])\n",
            "tensor(49.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([33.])   tensor([40])\n",
            "tensor(49.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([50.])   tensor([40])\n",
            "tensor(100.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([33.])   tensor([40])\n",
            "tensor(49.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([47.])   tensor([40])\n",
            "tensor(49.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([32.])   tensor([40])\n",
            "tensor(64.)\n",
            "tensor([32.])   tensor([40])\n",
            "tensor(64.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([38.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([30.])   tensor([40])\n",
            "tensor(100.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([35.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([43.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([36.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([45.])   tensor([40])\n",
            "tensor(25.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([40.])   tensor([40])\n",
            "tensor(0.)\n",
            "tensor([44.])   tensor([40])\n",
            "tensor(16.)\n",
            "tensor([41.])   tensor([40])\n",
            "tensor(1.)\n",
            "tensor([37.])   tensor([40])\n",
            "tensor(9.)\n",
            "tensor([42.])   tensor([40])\n",
            "tensor(4.)\n",
            "Average loss is  12.966887417218542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUDb1f-ayt8f"
      },
      "source": [
        "#See Progress\n",
        "index=-1\n",
        "for img, label in test:\n",
        "  index+=1\n",
        "  if (True):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img.squeeze(), cmap='gray', vmin = 0, vmax = 1)\n",
        "    ax = plt.gca()\n",
        "    ax.set_xticks(np.arange(0, 80, 5))\n",
        "    plt.grid(color='b', linewidth=2)\n",
        "    plt.show()\n",
        "    out = model(img) # forward pass\n",
        "    label=label.unsqueeze(0)\n",
        "    label=torch.reshape(label,out.shape)\n",
        "    print(label,\" \",out)\n",
        "    \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "276vHsG8Qqov"
      },
      "source": [
        "print(len(valid))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
